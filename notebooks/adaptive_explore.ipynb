{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89f344f6-a831-40cf-83b7-76b4bfde5e96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from statistics import mean\n",
    "from transformers import T5Tokenizer\n",
    "from src.tfr_decoding.pairwise_modeling import T5BinaryClassifier, validate\n",
    "import numpy as np\n",
    "import torch\n",
    "from itertools import combinations\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import spearmanr, kendalltau\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "905710fc-b7b7-487f-9a12-d8aa84718e0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e437cc6-7b3a-4ee6-bebb-4cf5a08f7a72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained(\"google/flan-t5-xxl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483ca16f-475f-425f-84d1-897c4c0c33de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pfmod_path = \"./lightning_logs/multimodel/checkpoints/epoch=3-step=86946.ckpt\"\n",
    "pfname = 'stanfordnlp/SteamSHP-flan-t5-large'\n",
    "# get prefix model\n",
    "qpref = T5BinaryClassifier.load_from_checkpoint(pfmod_path).to(\"cuda:1\")\n",
    "preftok = T5Tokenizer.from_pretrained(pfname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6fe87ad4-d505-464d-a8f5-9a451c0fc55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_toklen_lists(indf, tok):\n",
    "    res = []\n",
    "    for h in indf.hyps:\n",
    "        lens = [len(tok(hyp).input_ids) for hyp in h]\n",
    "        res.append(lens)\n",
    "    return res\n",
    "\n",
    "def make_prefs(indf, tok, pflen):\n",
    "    res = []\n",
    "    for h in indf.hyps:\n",
    "        prefs = [tok.decode(tok(hyp).input_ids[:pflen], skip_special_tokens=True) for hyp in h]\n",
    "        res.append(prefs)\n",
    "    return res\n",
    "\n",
    "def adaptbase(inpdf, thresh, mrange):\n",
    "    inds = list(range(8))\n",
    "    fscos = []\n",
    "    budgets = []\n",
    "    for ind in range(len(inpdf)):\n",
    "        slist = inpdf.scos[ind]\n",
    "        blist = inpdf.toklens[ind]\n",
    "        random.shuffle(inds)\n",
    "        tmp = []\n",
    "        budget = 0\n",
    "        # get adaptive score\n",
    "        for i in inds[:mrange]:\n",
    "            budget = budget+blist[i]\n",
    "            if slist[i]>thresh:\n",
    "                fscos.append(slist[i])\n",
    "                break\n",
    "            tmp.append(slist[i])\n",
    "            if i==inds[mrange-1]:\n",
    "                fscos.append(max(tmp))\n",
    "        budgets.append(budget)\n",
    "    return mean(fscos), mean(budgets)\n",
    "\n",
    "def samprer(inpdf, mrange):\n",
    "    inds = list(range(8))\n",
    "    fscos = []\n",
    "    budgets = []\n",
    "    for ind in range(len(inpdf)):\n",
    "        slist = inpdf.scos[ind]\n",
    "        blist = inpdf.toklens[ind]\n",
    "        random.shuffle(inds)\n",
    "        tmp = []\n",
    "        budget = 0\n",
    "        fscos.append(max([slist[i] for i in inds[:mrange]]))\n",
    "        budgets.append(sum([blist[i] for i in inds[:mrange]]))\n",
    "        \n",
    "    return mean(fscos), mean(budgets)\n",
    "\n",
    "def adaptive_prefsort(inpdf, thresh, mrange, pf, hstop):\n",
    "    inds = list(range(8))\n",
    "    fscos = []\n",
    "    budgets = []\n",
    "    for ind in range(len(inpdf)):\n",
    "        # score list and list of budgets\n",
    "        slist = inpdf.scos[ind]\n",
    "        blist = inpdf.toklens[ind]\n",
    "        # list with prefix metric scores (specifically final class)\n",
    "        plist = [a[-1] for a in inpdf[\"probs\"+str(pf)][ind]]\n",
    "        # mix up what order we get stuff in\n",
    "        random.shuffle(inds)\n",
    "        tmp = []\n",
    "        # get prob values\n",
    "        nplist = [plist[p] for p in inds[:mrange]]\n",
    "        \n",
    "        # get indices to use\n",
    "        sortps = [inds[pl] for pl in np.argsort(nplist)]\n",
    "        sortps.reverse()\n",
    "        # if ind==0:\n",
    "        #     print(plist)\n",
    "        #     print(slist)\n",
    "        #     print(sortps)\n",
    "        budget = pf*mrange\n",
    "        # get adaptive score\n",
    "        for i in sortps[:hstop]:\n",
    "            budget = budget+blist[i]\n",
    "            budget = budget-pf # already part of budget, remove\n",
    "            if slist[i]>thresh:\n",
    "                fscos.append(slist[i])\n",
    "                break\n",
    "            tmp.append(slist[i])\n",
    "            if i==sortps[hstop-1]:\n",
    "                fscos.append(max(tmp))\n",
    "        budgets.append(budget)\n",
    "    return mean(fscos), mean(budgets)\n",
    "\n",
    "def adaptive_ranksort(inpdf, thresh, mrange, pf, hstop):\n",
    "    inds = list(range(8))\n",
    "    fscos = []\n",
    "    budgets = []\n",
    "    for ind in range(len(inpdf)):\n",
    "        # score list and list of budgets\n",
    "        slist = inpdf.scos[ind]\n",
    "        blist = inpdf.toklens[ind]\n",
    "        # list with prefix metric scores (specifically final class)\n",
    "        pdict = inpdf['pairdict'+str(pf)][ind]\n",
    "        # mix up what order we get stuff in\n",
    "        random.shuffle(inds)\n",
    "        tmp = []\n",
    "        # get prob values\n",
    "        sortps, sortcnts = rank_pairwise(pdict, inds[:mrange])\n",
    "        # if ind==0:\n",
    "        #     print(plist)\n",
    "        #     print(slist)\n",
    "        #     print(sortps)\n",
    "        budget = pf*mrange\n",
    "        # get adaptive score\n",
    "        for i in sortps[:hstop]:\n",
    "            budget = budget+blist[i]\n",
    "            budget = budget-pf # already part of budget, remove\n",
    "            if slist[i]>thresh:\n",
    "                fscos.append(slist[i])\n",
    "                break\n",
    "            tmp.append(slist[i])\n",
    "            if i==sortps[hstop-1]:\n",
    "                fscos.append(max(tmp))\n",
    "        budgets.append(budget)\n",
    "    return mean(fscos), mean(budgets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16107b3b-c999-4a78-a827-944d284bfd0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.argsort([3, 4, 2, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd5daa74-4d8a-4027-bfc1-a1df90cb6bde",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if True:\n",
    "    fulld = pd.read_json(\"output/adapt_explore.jsonl\", orient=\"records\", lines=True)\n",
    "else:\n",
    "    # load in data\n",
    "    d1 = pd.read_json(\"output/testset1.jsonl\", orient=\"records\", lines=True).drop(columns=[\"stats\", 'ver', 'pref'])\n",
    "    d2 = pd.read_json(\"output/testset2.jsonl\", orient=\"records\", lines=True).drop(columns=[\"stats\", 'ver', 'pref'])\n",
    "    fulld = pd.DataFrame({'inp':d1.inp, 'hyps':[d1['hyps'][i]+d2['hyps'][i] for i in range(len(d1))], 'scos':[d1['scos'][i]+d2['scos'][i] for i in range(len(d1))]})\n",
    "    fulld['toklens'] = make_toklen_lists(fulld, tokenizer)\n",
    "    fulld['pf5'] = make_prefs(fulld, tokenizer, 5)\n",
    "    fulld['pf10'] = make_prefs(fulld, tokenizer, 10)\n",
    "    fulld['pf15'] = make_prefs(fulld, tokenizer, 15)\n",
    "    fulld['pf20'] = make_prefs(fulld, tokenizer, 20)\n",
    "    fulld.to_json(\"output/adapt_explore.jsonl\", orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be6ad978-4075-4c42-b812-cfaf55076fc6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to construct a DataFrame with pairs\n",
    "def construct_pair_dset(row, hcol):\n",
    "    # go through all possible pairs\n",
    "    all_pairs = list(combinations(range(len(row[hcol])), 2))\n",
    "    pairs = [(row[hcol][i], row[hcol][j]) for i, j in all_pairs]\n",
    "    scores = [(row['scos'][i], row['scos'][j]) for i, j in all_pairs]\n",
    "\n",
    "    label = [score_a > score_b for score_a, score_b in scores]\n",
    "    df_temp = pd.DataFrame({'inp': row['inp'], 'hyp_pairs': pairs,\n",
    "                            'score_a': [s[0] for s in scores],\n",
    "                            'score_b': [s[1] for s in scores],\n",
    "                            'label': label, 'pair_id':[str(s[0])+\"_\"+str(s[1]) for s in all_pairs]})\n",
    "    return df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7283d03b-3361-474c-9a61-60568915525e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pairdf = pd.concat([construct_pair_dset(row, 'pf20') for _,row in fulld.iterrows()]).reset_index(drop=True)\n",
    "pairdf[['hyp_a', 'hyp_b']] = pd.DataFrame(pairdf['hyp_pairs'].tolist(), index=pairdf.index)\n",
    "pairdf = pairdf.drop('hyp_pairs', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8db844c5-f65d-4e8c-8778-aab519f4167d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "CLASSES = [71, 272]\n",
    "def pairlabel(val):\n",
    "    if val==1:\n",
    "        return CLASSES[0]\n",
    "    return CLASSES[1]\n",
    "\n",
    "pairdf['numlab'] = pairdf.label\n",
    "pairdf['label'] = [pairlabel(p) for p in pairdf.numlab]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "566ad74c-605b-41de-b1b0-32fe6215e59b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA RTX A6000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "Restoring states from the checkpoint path at lightning_logs/balanced_compmodel/checkpoints/epoch=4-step=36732.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "Loaded model weights from the checkpoint at lightning_logs/balanced_compmodel/checkpoints/epoch=4-step=36732.ckpt\n",
      "/home/prasann/miniconda3/envs/rewardenv/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 28 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d7927cbecee426a8af8cc7206311500",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "     Validate metric           DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      val_accuracy          0.7033439881976887\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    }
   ],
   "source": [
    "# get labels, probs for all pairs\n",
    "preds, labels, probs = validate(pairdf, \"lightning_logs/balanced_compmodel/checkpoints/epoch=4-step=36732.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3eed1d6a-4312-45c3-a629-f4b3ddab3025",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pairdf['pred20'] = preds\n",
    "pairdf['prob20'] = probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c4d8aa8-d270-4f3c-8928-4d1225f8b814",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pairdf.to_json(\"output/adapt2_pairwise20.jsonl\", orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d8f5e202-4e95-4d38-ac35-20b61f811225",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dists = (pairdf.score_a - pairdf.score_b).abs()\n",
    "selprobs = [max(m) for m in pairdf.prob20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "421bf272-6eb8-4d11-bdf1-de86eb1ed617",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pairdf['dists'] = dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ddd9d0e8-c563-411f-8598-3335955d4971",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8151694594935114"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bdist = pairdf[pairdf.dists>0.1]\n",
    "(bdist['pred20']==bdist['label']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ed248156-2b9b-448a-9590-66a5f3da00a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "CLASSES = [71, 272]\n",
    "g_dicts = []\n",
    "for i in range(len(fulld)):\n",
    "    g = pairdf[pairdf.inp==fulld.inp.iloc[i]]\n",
    "    tmpdict = {}\n",
    "    for i in range(len(g)):\n",
    "        tmpdict[g['pair_id'].iloc[i]] = 1-CLASSES.index(g['pred20'].iloc[i])\n",
    "    g_dicts.append(tmpdict)\n",
    "fulld['pairdict20'] = g_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ca7c4dc2-8c89-4ea1-a65c-9e3c5db4fa5d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def getprobs(indf, ex):\n",
    "    allprobs = []\n",
    "    for num in range(8):\n",
    "        out = qpref.predsingle(indf['inp'][ex], indf['pf20'][ex][num], True)\n",
    "        cprobs = []\n",
    "        for c in CLASSES:\n",
    "            out.sequences[0][1] = c\n",
    "            transition_scores = qpref.model.compute_transition_scores(\n",
    "                out.sequences, out.scores, normalize_logits=True\n",
    "            )\n",
    "            cprobs.append(float(np.exp(transition_scores[0][0].cpu())))\n",
    "        allprobs.append(cprobs)\n",
    "    return allprobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e92ff7f4-c94f-48e5-b89d-8c580d40a043",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rank_pairwise(compdict, include=[0, 1, 2, 3, 4, 5, 6, 7]):\n",
    "    include = [str(s) for s in include]\n",
    "    # Create a dictionary to count votes for each index\n",
    "    vote_count = defaultdict(int)\n",
    "    for i in include:\n",
    "        vote_count[str(i)]=0\n",
    "\n",
    "    # Process the comparisons\n",
    "    for pair, label in compdict.items():\n",
    "        #print(pair)\n",
    "        #print(label)\n",
    "        # Split the pair into individual indices\n",
    "        indices = pair.split(\"_\")\n",
    "        if indices[0] in include and indices[1] in include:\n",
    "            # Assign the vote to the correct index\n",
    "            if label == 1:\n",
    "                vote_count[indices[0]] += 1\n",
    "            else:\n",
    "                vote_count[indices[1]] += 1\n",
    "    #print(vote_count)\n",
    "    # Convert to a list of tuples and sort in descending order by vote count\n",
    "    sorted_indices = sorted(vote_count.items(), key=lambda x: x[1], reverse=True)\n",
    "    indices = [int(ind) for ind, _ in sorted_indices] \n",
    "    counts = [count for _, count in sorted_indices] \n",
    "    # Print the sorted indices\n",
    "    #for index, count in sorted_indices:\n",
    "    #    print(f\"Index {index} with vote count {count}\")\n",
    "    return indices, counts\n",
    "\n",
    "def pred_best_n(n):\n",
    "    allpreds = []\n",
    "    allgolds = []\n",
    "    allrands = []\n",
    "    for ind in range(len(fulld)):\n",
    "        inds, counts = rank_pairwise(g_dicts[ind])\n",
    "        scovals = fulld.scos.iloc[ind]\n",
    "        goldranks = list(np.argsort(scovals))\n",
    "        allgolds.append(max([scovals[s] for s in goldranks[-1*n:]]))\n",
    "        allpreds.append(max([scovals[s] for s in inds[:n]]))\n",
    "        random.shuffle(inds)\n",
    "        allrands.append(max([scovals[s] for s in inds[:n]]))\n",
    "    return mean(allgolds), mean(allpreds), mean(allrands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f6de0d-fb5b-4f6c-8422-979f97698d5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "a = [1, 2, 3]\n",
    "a[-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2289f3e6-6b32-4a99-9c6a-7f0ed47ce40d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9002139297487092, 0.8834123045165233, 0.8287699305666093)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_best_n(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105a5210-99ce-4085-b6b5-157575632809",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fulld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9415e897-010e-4a39-b7ef-3867be127886",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pairdf[pairdf.inp==fulld.inp.iloc[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c3c31b-f349-4f0e-b7c9-94dd326f2129",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rank_pairwise(g_dicts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f52ca7-8521-4746-98ee-108a33773827",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    allprobs = []\n",
    "    for val in range(len(fulld)):\n",
    "        if val%10==0:\n",
    "            print(val)\n",
    "        allprobs.append(getprobs(fulld, val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3043dce9-997a-4468-bf11-f381a259a2e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fulld['probs20'] = allprobs\n",
    "fulld.to_json(\"output/adapt_explore.jsonl\", orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fddacbc-ae43-41c5-89f2-d8fb297e2717",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fulld.scos[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19cd9308-adc9-4706-843c-35af37f52e3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "getprobs(fulld, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8466e99-5885-4a24-8b0f-c65e30ec2851",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "transition_scores = qpref.model.compute_transition_scores(\n",
    "    out.sequences, out.scores, normalize_logits=True\n",
    ")\n",
    "print(np.exp(transition_scores[0][0].cpu()))\n",
    "print(np.argmax(out.scores[0].cpu()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e0840527-671a-4c09-ba84-8a18ec37f56e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "CLASSES = [71, 272, 205, 309]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d056fb9a-c8ea-4fa3-88a5-75976be5f7ac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8041931372659045   94.44742685025818\n",
      "0.8229735549667913   116.10885197934596\n",
      "0.8347407183849952   137.5811308089501\n",
      "0.8429356585925766   158.49361617900172\n",
      "0.8494724683492553   179.53176936316694\n",
      "0.854479042185624   200.31748192771084\n",
      "0.8587141485635704   220.94034767641998\n"
     ]
    }
   ],
   "source": [
    "## run adaptive baseline\n",
    "for j in range(2, 9):\n",
    "    scos, buds = [], []\n",
    "    for i in range(1000):\n",
    "        s, b = adaptive_ranksort(fulld, .85, j, 20, 1)\n",
    "        # s, b = samprer(fulld,  j)\n",
    "        scos.append(s)\n",
    "        buds.append(b)\n",
    "    print(mean(scos), \" \", mean(buds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85cf2fb0-506b-4446-8368-fa573ea64cd0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mean([max(m) for m in fulld.scos])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d00e54-3319-4c36-9a8b-f68053bcea95",
   "metadata": {},
   "outputs": [],
   "source": [
    "0.8267750212205238   119.82409810671257\n",
    "0.8447314879783238   139.1265800344234\n",
    "0.8548433872520032   158.27455421686747\n",
    "0.8619431309783976   177.52356798623063\n",
    "0.8674830498737955   196.6789586919105\n",
    "0.8720366012693377   215.81833734939758\n",
    "0.8760026756320878   234.8388760757315"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
