{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac9e2f86-5d35-4886-84a6-c338f94b3b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-06 05:41:26.708999: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-02-06 05:41:26.709028: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoTokenizer\n",
    "from src.utils.score_utils import metrics_mapping\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea975e55-7c9c-4f67-bec1-46f3bb380ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "devcands = pd.read_csv(\"/mnt/data1/prasann/latticegen/lattice-generation/COMET/data/PARPREFIX_DEV.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f55da39-c479-49ee-a3a9-18c8de084ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "devcands = devcands.rename(columns={\"mt\":\"hyp\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ee6566a-d4b7-418f-87e7-88e259320d6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66814"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(devcands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d3d3f5a-bf71-4ae5-a936-3b382d1d8df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmpcands = devcands[devcands['plen']<13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "34d66ca0-0ea5-42bb-bcb9-fea4e89b9622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81.40172364641126 %\n",
      "82.8052016403149 %\n",
      "84.20867963421856 %\n",
      "85.61215762812219 %\n",
      "87.01563562202583 %\n",
      "88.41911361592948 %\n",
      "89.82259160983311 %\n",
      "91.22606960373676 %\n",
      "92.62954759764041 %\n",
      "94.03302559154405 %\n",
      "95.43650358544768 %\n",
      "96.83998157935133 %\n",
      "98.24345957325498 %\n",
      "99.64693756715862 %\n",
      "TOOK TIME  1841.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/data1/prasann/tfr-decoding/src/utils/score_utils.py:313: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tset[metric] = get_scores_auto(hyps, srcs, refs, \"parentqe\", \"comstyle\")\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    metrics_mapping(\"pqe\", tmpcands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2afbc141-1001-455c-a708-ee53d995c237",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmpcands = pd.read_csv(\"prefix_scored.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "550047d5-c089-4c34-b46e-730c59d3629d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#allcands = pd.read_csv(\"tmp.csv\", index_col=0)\n",
    "def rer_met(rer, tgt, df, preflen):\n",
    "    N=1\n",
    "    tmp = df[df['plen']==preflen]\n",
    "    print(tmp[tgt].mean())\n",
    "    fsort = tmp.sort_values(by=['ref', rer], ascending=[True, False]).groupby('ref', as_index=False).nth[:N]\n",
    "    return fsort[tgt].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "655a425f-de3b-4c47-8995-8cf8c1ffb7f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6357526586236814\n",
      "0.6622992265826895\n",
      "0.6357526586236814\n",
      "0.6771156381147742\n"
     ]
    }
   ],
   "source": [
    "print(rer_met(\"prefpqe\", \"score\", tmpcands, 9))\n",
    "print(rer_met(\"pqe\", \"score\", tmpcands, 9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2d39af95-8841-4511-b3e3-583b78f96644",
   "metadata": {},
   "outputs": [],
   "source": [
    "#testcands = list(allcands['hyp'][:50])\n",
    "#testscos = list(allcands['precision'][:50])\n",
    "tok = AutoTokenizer.from_pretrained(\"facebook/bart-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ecb47fd9-e117-4a78-8097-add1c9e2c464",
   "metadata": {},
   "outputs": [],
   "source": [
    "allcands = allcands.drop(columns=['precision', 'recall', 'f1'])\n",
    "allcands = allcands.loc[allcands.hyp.apply(lambda x: isinstance(x, str))]\n",
    "allcands = allcands.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "736b2686-5afc-4d09-b175-1a1489e143dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "546000\n",
      "547000\n",
      "548000\n",
      "549000\n",
      "550000\n",
      "551000\n",
      "552000\n",
      "553000\n",
      "554000\n",
      "555000\n",
      "556000\n",
      "557000\n",
      "558000\n",
      "559000\n",
      "560000\n",
      "561000\n",
      "562000\n",
      "563000\n",
      "564000\n",
      "565000\n",
      "566000\n",
      "567000\n",
      "568000\n",
      "569000\n",
      "570000\n",
      "571000\n",
      "572000\n",
      "573000\n",
      "574000\n",
      "575000\n",
      "576000\n",
      "577000\n",
      "578000\n",
      "579000\n",
      "580000\n",
      "581000\n",
      "582000\n",
      "583000\n",
      "584000\n",
      "585000\n",
      "586000\n",
      "587000\n",
      "588000\n",
      "589000\n",
      "590000\n",
      "591000\n",
      "592000\n",
      "593000\n",
      "594000\n",
      "595000\n",
      "596000\n",
      "597000\n",
      "598000\n",
      "599000\n",
      "600000\n",
      "601000\n",
      "602000\n",
      "603000\n",
      "604000\n",
      "605000\n",
      "606000\n",
      "607000\n",
      "608000\n",
      "609000\n",
      "610000\n",
      "611000\n",
      "612000\n",
      "613000\n",
      "614000\n",
      "615000\n",
      "616000\n",
      "617000\n",
      "618000\n",
      "619000\n",
      "620000\n",
      "621000\n",
      "622000\n",
      "623000\n",
      "624000\n",
      "625000\n",
      "626000\n",
      "627000\n",
      "628000\n",
      "629000\n",
      "630000\n",
      "631000\n",
      "632000\n",
      "633000\n",
      "634000\n",
      "635000\n",
      "636000\n",
      "637000\n",
      "638000\n",
      "639000\n",
      "640000\n",
      "641000\n",
      "642000\n",
      "643000\n",
      "644000\n",
      "645000\n",
      "646000\n",
      "647000\n",
      "648000\n",
      "649000\n",
      "650000\n",
      "651000\n",
      "652000\n",
      "653000\n",
      "654000\n",
      "655000\n",
      "656000\n",
      "657000\n",
      "658000\n",
      "659000\n",
      "660000\n",
      "661000\n",
      "662000\n",
      "663000\n",
      "664000\n",
      "665000\n",
      "666000\n",
      "667000\n",
      "668000\n",
      "669000\n",
      "670000\n",
      "671000\n",
      "672000\n",
      "673000\n",
      "674000\n",
      "675000\n",
      "676000\n",
      "677000\n",
      "678000\n",
      "679000\n",
      "680000\n",
      "681000\n",
      "682000\n",
      "683000\n",
      "684000\n",
      "685000\n",
      "686000\n",
      "687000\n",
      "688000\n",
      "689000\n",
      "690000\n",
      "691000\n",
      "692000\n",
      "693000\n",
      "694000\n",
      "695000\n",
      "696000\n",
      "697000\n",
      "698000\n",
      "699000\n",
      "700000\n",
      "701000\n",
      "702000\n",
      "703000\n",
      "704000\n",
      "705000\n",
      "706000\n",
      "707000\n",
      "708000\n",
      "709000\n",
      "710000\n",
      "711000\n",
      "712000\n",
      "713000\n",
      "714000\n",
      "715000\n",
      "716000\n",
      "717000\n",
      "718000\n",
      "719000\n",
      "720000\n",
      "721000\n",
      "722000\n",
      "723000\n",
      "724000\n",
      "725000\n",
      "726000\n",
      "727000\n",
      "728000\n",
      "729000\n",
      "730000\n",
      "731000\n",
      "732000\n",
      "733000\n",
      "734000\n",
      "735000\n",
      "736000\n",
      "737000\n",
      "738000\n",
      "739000\n",
      "740000\n",
      "741000\n",
      "742000\n",
      "743000\n",
      "744000\n",
      "745000\n",
      "746000\n",
      "747000\n",
      "748000\n",
      "749000\n",
      "750000\n",
      "751000\n",
      "752000\n",
      "753000\n",
      "754000\n",
      "755000\n",
      "756000\n",
      "757000\n",
      "758000\n",
      "759000\n",
      "760000\n",
      "761000\n",
      "762000\n",
      "763000\n",
      "764000\n",
      "765000\n",
      "766000\n",
      "767000\n",
      "768000\n",
      "769000\n",
      "770000\n",
      "771000\n",
      "772000\n",
      "773000\n",
      "774000\n",
      "775000\n",
      "776000\n",
      "777000\n",
      "778000\n",
      "779000\n",
      "780000\n",
      "781000\n",
      "782000\n",
      "783000\n",
      "784000\n",
      "785000\n",
      "786000\n",
      "787000\n",
      "788000\n",
      "789000\n",
      "790000\n",
      "791000\n",
      "792000\n",
      "793000\n",
      "794000\n",
      "795000\n",
      "796000\n",
      "797000\n",
      "798000\n",
      "799000\n",
      "800000\n",
      "801000\n",
      "802000\n",
      "803000\n",
      "804000\n",
      "805000\n",
      "806000\n",
      "807000\n",
      "808000\n",
      "809000\n",
      "810000\n",
      "811000\n",
      "812000\n",
      "813000\n",
      "814000\n",
      "hyps processed\n",
      "<module 'tqdm' from '/home/prasann/miniconda3/envs/latclone/lib/python3.8/site-packages/tqdm/__init__.py'>\n",
      "Using 4 processes, starting now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing PARENT: 100%|█████████████████████████████████████████████| 814577/814577 [04:36<00:00, 2949.77it/s]\n"
     ]
    }
   ],
   "source": [
    "metrics_mapping(\"parent\", allcands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8b5826d5-85e4-4891-8044-0a57ee7af755",
   "metadata": {},
   "outputs": [],
   "source": [
    "allcands.to_csv(\"updated_dset_full.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d876e73-ab8c-4f85-a33d-802657afd425",
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore how well scores of prefixes predicts which choice will lead to something good down the line\n",
    "# TODO use Jiacheng's code for beam search latticification?\n",
    "# TODO use the T5 t2t generation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0a0c9fe6-2365-4be4-8e5b-ea6cbdd8d40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_prefixes(cands, tok):\n",
    "    return None\n",
    "    \n",
    "def tok_str(toks):\n",
    "    s = \"\"\n",
    "    for t in toks:\n",
    "        s = s+str(t)+\"_\"\n",
    "    return s[:-1]\n",
    "\n",
    "def get_prefs_info(pint, tokd, scos):\n",
    "    infos = {}\n",
    "    for t in range(len(tokd)):\n",
    "        if len(tokd[t])<pint:\n",
    "            continue\n",
    "        k = tok_str(tokd[t][:pint]) # get prefix key\n",
    "        # for each prefix, track inds of cands w that prefix\n",
    "        if k in infos:\n",
    "            infos[k].append(scos[t])\n",
    "        else:\n",
    "            infos[k] = [scos[t]]\n",
    "    \n",
    "    return infos\n",
    "\n",
    "def get_prefix_data(tokd, scos, plen, tok):\n",
    "    pinfo = get_prefs_info(plen, tokd, scos)\n",
    "    result = []\n",
    "    for inf in pinfo.keys():\n",
    "        # get usable prefix string\n",
    "        pref = tok.decode([int(f) for f in inf.split(\"_\")])\n",
    "        # each prefix associated with best possibility\n",
    "        result.append({\n",
    "            \"inp\":pref,\n",
    "            \"scos\":pinfo[inf],\n",
    "            \"sco\":max(pinfo[inf]),\n",
    "            \"plen\":plen\n",
    "        })\n",
    "    return result\n",
    "\n",
    "# given selected part of df, get prefix data\n",
    "def ex_dset(exs, plen, tok):\n",
    "    tokd = tok(list(exs['hyp']), add_special_tokens=False).input_ids\n",
    "    maxl = max(len(t) for t in tokd)\n",
    "    pind = plen\n",
    "    pdata = []\n",
    "    while pind<maxl:\n",
    "        pdata.extend(get_prefix_data(tokd, list(exs['precision']), pind, tok))\n",
    "        pind+=plen\n",
    "    result = pd.DataFrame(pdata)\n",
    "    result['src'] = exs['src'].iloc[0]\n",
    "    result['ref'] = exs['ref'].iloc[0]\n",
    "    return result\n",
    "    \n",
    "def get_full_dset(acands, plen, tok):\n",
    "    alldfs = []\n",
    "    uns = acands['ref'].unique()\n",
    "    ind = 0\n",
    "    lens = []\n",
    "    print(len(uns))\n",
    "    for u in uns:\n",
    "        try:\n",
    "            alldfs.append(ex_dset(acands[acands['ref']==u], plen, tok))\n",
    "            ind+=1\n",
    "        except:\n",
    "            print(\"anomaly\")\n",
    "        if ind%1000==0:\n",
    "            print(ind)\n",
    "    return pd.concat(alldfs), [len(adf) for adf in alldfs]\n",
    "\n",
    "# TODO remember to remove add_special_tokens when tokenizing\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "00d01322-7f0a-4b9a-9f1c-2d67ce110d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16242\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n"
     ]
    }
   ],
   "source": [
    "fullset, lens = get_full_dset(allcands, 3, tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9ccbb9a4-0976-4b8b-b7dc-e4662a12ef47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fullset.to_csv(\"prefix_dset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd2b7ae2-ef81-43cc-892b-c81451bd4f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "fullset = pd.read_csv(\"prefix_dset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dcee2998-21b4-4747-aff0-008871f0c6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fullset = fullset.rename(columns={'sco':'score', \"inp\":\"mt\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0b9def9-65f4-4b2c-8256-6688b6647871",
   "metadata": {},
   "outputs": [],
   "source": [
    "split = int(len(fullset)*.8)\n",
    "devsize = int(len(fullset)*.95)\n",
    "\n",
    "trainset = fullset.iloc[:split].sample(frac=1).reset_index()\n",
    "devset = fullset.iloc[devsize:].sample(frac=1).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa76ec24-1b04-45fb-b7db-4b23f40a0932",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset.to_csv(\"/mnt/data1/prasann/latticegen/lattice-generation/COMET/data/PARPREFIX_TRAIN.csv\")\n",
    "devset.to_csv(\"/mnt/data1/prasann/latticegen/lattice-generation/COMET/data/PARPREFIX_DEV.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fc68404f-fb6a-423d-a143-b46450dc56a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "infos = get_prefs_info(10, tokd, testscos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "60e2fec1-55c3-437f-a7de-0843125c6ba5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0_287_1843_8_2708_20484_459_9429_446_34_': [0.7275104059794265,\n",
       "  0.8043923419964522,\n",
       "  0.7501542733805745,\n",
       "  0.7022985883539701,\n",
       "  1.0,\n",
       "  0.8043923419964522,\n",
       "  0.791947919692525,\n",
       "  0.6355653131400284,\n",
       "  1.0,\n",
       "  0.8857000285382948,\n",
       "  0.6652049901111008,\n",
       "  0.8881501211769413],\n",
       " '0_20_34177_12270_11_5_496_10315_9_15541_': [1.0,\n",
       "  0.874235093122898,\n",
       "  0.874235093122898,\n",
       "  0.7949253342322761,\n",
       "  0.874235093122898],\n",
       " '0_20_34177_12270_9_287_1843_8_2708_20484_': [0.8560118665583999,\n",
       "  0.8153343052686353,\n",
       "  0.8153551038173115,\n",
       "  0.7328616209964707],\n",
       " '0_287_1843_8_2708_20484_459_9429_446_16_': [0.7679249640195699,\n",
       "  0.6975863464034741,\n",
       "  0.7679249640195699,\n",
       "  0.8012120435729666,\n",
       "  0.781285189930025,\n",
       "  0.7679249640195699,\n",
       "  0.7679249640195699,\n",
       "  0.825189076232105,\n",
       "  0.8043923419964522,\n",
       "  0.8209592487442797,\n",
       "  0.7306804610333764,\n",
       "  0.7679249640195699,\n",
       "  0.7080321137411774,\n",
       "  0.6975863464034741,\n",
       "  0.7679249640195699],\n",
       " '0_20_34177_12270_13_287_1843_8_2708_20484_': [0.8811286209119195],\n",
       " '0_20_34177_12270_9_5_287_1843_8_2708_': [0.7821467668928538],\n",
       " '0_20_34177_12270_13_5_287_1843_8_2708_': [0.7821467668928538],\n",
       " '0_287_1843_8_2708_20484_459_9429_446_34177_': [0.8884549608034874],\n",
       " '0_287_1843_8_2708_20484_459_9429_446_18_': [0.874235093122898],\n",
       " '0_287_1843_8_2708_20484_459_9429_446_21_': [0.6642750214037211],\n",
       " '0_20_5135_346_11_5_496_10315_9_15541_': [0.8065008590125561],\n",
       " '0_287_1843_8_2708_20484_459_9429_446_5135_': [0.7772028634815905],\n",
       " '0_287_1843_8_2708_20484_459_9429_446_36_': [0.6162607099729586],\n",
       " '0_20_5135_346_9_287_1843_8_2708_20484_': [0.7561559858236034],\n",
       " '0_287_1843_8_2708_20484_459_9429_446_6_': [0.6075172081657922],\n",
       " '0_287_1843_8_2708_20484_459_9429_446_64_': [0.4838082460796165,\n",
       "  0.7344197919070947],\n",
       " '0_20_5135_346_13_287_1843_8_2708_20484_': [0.781285189930025]}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f9c19b-673a-45b0-b415-765226fa9fdf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
